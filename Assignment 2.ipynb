{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d453ee04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.Ship of Theseus(2012)</td>\n",
       "      <td>8</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.Iruvar(1997)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.Kaagaz Ke Phool(1959)</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.Lagaan: Once Upon a Time in India(2001)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.Pather Panchali(1955)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.Apur Sansar(1959)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.Kanchivaram(2008)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.Monsoon Wedding(2001)</td>\n",
       "      <td>7.3</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.Black(2005)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.Deewaar(1975)</td>\n",
       "      <td>8</td>\n",
       "      <td>(1975)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name rating   years\n",
       "0                     1.Ship of Theseus(2012)      8  (2012)\n",
       "1                              2.Iruvar(1997)    8.4  (1997)\n",
       "2                     3.Kaagaz Ke Phool(1959)    7.8  (1959)\n",
       "3   4.Lagaan: Once Upon a Time in India(2001)    8.1  (2001)\n",
       "4                     5.Pather Panchali(1955)    8.2  (1955)\n",
       "..                                        ...    ...     ...\n",
       "95                       96.Apur Sansar(1959)    8.4  (1959)\n",
       "96                       97.Kanchivaram(2008)    8.2  (2008)\n",
       "97                   98.Monsoon Wedding(2001)    7.3  (2001)\n",
       "98                             99.Black(2005)    8.1  (2005)\n",
       "99                          100.Deewaar(1975)      8  (1975)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send request to the URL and get the response\n",
    "url = \"https://www.imdb.com/list/ls056092300/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "#name=soup.(\"h3\",class_=\"lister-item-header\")\n",
    "#name.text.replace(\"\\n\", \"\")\n",
    "\n",
    "#rating=soup.find(\"div\",class_=\"ipl-rating-star small\")\n",
    "#rating.text.replace(\"\\n\",\"\")\n",
    "\n",
    "#year=soup.find(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "#year=year.text.replace(\"(\", \"\")\n",
    "#year.replace(\")\",\"\")\n",
    "\n",
    "\n",
    "name=[]\n",
    "for i in soup.find_all(\"h3\",class_=\"lister-item-header\"):\n",
    "    name.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "years=[]\n",
    "for i in soup.find_all(\"span\",class_=\"lister-item-year text-muted unbold\"):\n",
    "    years.append(i.text.replace(\"/n\",\"\"))\n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"ipl-rating-star small\"):\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "df=pd.DataFrame({\"name\":name,\"rating\":rating,\"years\":years})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91676a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m     discount\u001b[38;5;241m.\u001b[39mappend(i\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     26\u001b[0m discount\n\u001b[1;32m---> 28\u001b[0m df1\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m:product,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m:price,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscount\u001b[39m\u001b[38;5;124m\"\u001b[39m:discount})\n\u001b[0;32m     29\u001b[0m df1\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#2\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url= \"https://peachmode.com/search?q=bags\"\n",
    "response = requests.get(url)       \n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "product=[]\n",
    "for i in soup.find_all(\"div\",class_=\"product-title\"):\n",
    "    product.append(i.text)\n",
    "\n",
    "price=[]\n",
    "for i in soup.find_all(\"span\",class_=\"price st-money money done\"):\n",
    "    price.append(i.text)\n",
    "    \n",
    "    \n",
    "discount=[]\n",
    "for i in soup.find_all(\"span\",class_=\"discounted_price st-money money done\"):\n",
    "    discount.append(i.text)\n",
    "    \n",
    "\n",
    "df1=pd.DataFrame({\"name\":product,\"price\":price,\"discount\":discount})\n",
    "df1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad999284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [heading, date, content, like]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url= \"https://www.patreon.com/coreyms\"\n",
    "response = requests.get(url) \n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "heading=[]\n",
    "for i in soup.find_all(\"span\",class_=\"sc-1hmaiaw-0 fIBzIT\"):\n",
    "    heading.append(i.text)\n",
    "    \n",
    "date=[]\n",
    "for i in soup.find_all(\"div\",class_=\"sc-mz8f26-0 gvyUof\"):\n",
    "    date.append(i.text)\n",
    "    \n",
    "content=[]\n",
    "for i in soup.find_all(\"div\",class_=\"sc-1ye87qi-0 bCBphS\"):\n",
    "    content.append(i.text)\n",
    "    \n",
    "like=[]\n",
    "for i in soup.find_all(\"div\",class_=\"sc-dJjYzT ggMBZu\"):\n",
    "    like.append(i.text)\n",
    "    \n",
    "df1=pd.DataFrame({\"heading\":heading,\"date\":date,\"content\":content,\"like\":like})\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c907232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url= \"https://www.patreon.com/coreyms\"\n",
    "response = requests.get(url) \n",
    "response\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "#soup\n",
    "\n",
    "heading=soup.find(\"span\",class_=\"sc-1hmaiaw-0 fIBzIT\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887e192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba63e974",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m,class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflex flex-col w-33pe items-center bo tp:w-half po:w-full border-r border-r-solid border-card-overview-border-color last:border-r-1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     27\u001b[0m     price\u001b[38;5;241m.\u001b[39mappend(i\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m---> 29\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhousetitle\u001b[39m\u001b[38;5;124m\"\u001b[39m:housetitle,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m:location,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memi\u001b[39m\u001b[38;5;124m\"\u001b[39m:emi,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m:price})\n\u001b[0;32m     30\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#5\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url= \"https://www.nobroker.in/property/rent/bangalore/multiple?searchParam=W3sibGF0IjoxMi45MzA3NzM1LCJsb24iOjc3LjU4MzgzMDIsInBsYWNlSWQiOiJDaElKMmRkbFo1Z1ZyanNSaDFCT0FhZi1vcnMiLCJwbGFjZU5hbWUiOiJKYXlhbmFnYXIifSx7ImxhdCI6MTIuOTc4MzY5MiwibG9uIjo3Ny42NDA4MzU2LCJwbGFjZUlkIjoiQ2hJSmtRTjNHS1FXcmpzUk5oQlFKcmhHRDdVIiwicGxhY2VOYW1lIjoiSW5kaXJhbmFnYXIifSx7ImxhdCI6MTIuOTgzMzA0LCJsb24iOjc3LjU2MDIzMSwicGxhY2VJZCI6IkNoSUpxVlJ2d19VOXJqc1JPVF9qNkN5NEt4MCIsInBsYWNlTmFtZSI6IlJhamFqaSBOYWdhciJ9XQ==&radius=2.0&sharedAccomodation=0&city=bangalore&locality=Jayanagar,Indiranagar,Rajaji%20Nagar\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "housetitle=[]\n",
    "\n",
    "for i in soup.find_all(\"a\",class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\"):   \n",
    "    housetitle.append(i.text)\n",
    "\n",
    "location=[]\n",
    "for i in soup.find_all(\"div\",class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0.1p po:max-w-95\"):\n",
    "    location.append(i.text)\n",
    "    \n",
    "emi=[]\n",
    "for i in soup.find_all(\"div\",class_=\"flex flex-col w-33pe items-center bo tp:w-half po:w-full border-r border-r-solid border-card-overview-border-color last:border-r-1\"):\n",
    "    emi.append(i.text)\n",
    "\n",
    "\n",
    "price=[]\n",
    "for i in soup.find_all(\"div\",class_=\"flex flex-col w-33pe items-center bo tp:w-half po:w-full border-r border-r-solid border-card-overview-border-color last:border-r-1\"):\n",
    "    price.append(i.text)\n",
    "    \n",
    "df=pd.DataFrame({\"housetitle\":housetitle,\"location\":location,\"emi\":emi,\"price\":price})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf771ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url=\"https://www.bewakoof.com/poco-x4-pro-5g-back-covers-cases\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "name=[]\n",
    "for i in soup.find_all(\"h2\",class_=\"clr-shade4 h3-p-name   undefined false  \"):\n",
    "    name.append(i.text)\n",
    "print(name)\n",
    "\n",
    "    \n",
    "df=pd.DataFrame({\"name\": name})\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de781126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heading</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We left the U.S. for Costa Rica and live bette...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/we-left-the-us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These are the 10 happiest cities in Americaâ€”no...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/happiest-citie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 3 most important things we're watching in ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/the-3-most-imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Busy ER doctors say these 8 sleep tips help th...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/busy-er-doctor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why millionaires may have hit their Social Sec...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/millionaires-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>College AI degree programs are booming.  Are t...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/college-ai-deg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stocks enter 'belief' phase with most investor...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/stocks-enter-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Newlywed couple went $44,000 into credit card ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/newlyweds-went...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Immigration is 'taking pressure off' the job m...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/immigration-ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Venture capital firm's plan to buy nonprofit h...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/heres-why-gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Top stocks to play the future of energy from a...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/top-stocks-to-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ride the bull market with these undervalued st...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/ride-the-bull-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How NescafÃ© instant coffee is made</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/how-nescaf-ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Upstart airlines Avelo and Breeze prepare for ...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/02/upstart-airlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OpenAI says in memo that Musk's claims â€˜stem f...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/openai-says-mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Waymo wins approval to expand robotaxi service...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/waymo-approved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CEO explains why RadNet is piloting mammogram ...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/ceo-explains-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cramer's Lightning Round: 'Not recommending' G...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cramer's week ahead: Watch for earnings from T...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/cramers-week-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Super Micro joining S&amp;P 500 after stock price ...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/super-micro-jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Change Healthcare sets up a new electronic pre...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/change-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lockheed Martin looks to acquire spacecraft ma...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/lockheed-marti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Google Gemini head removes social media profil...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/google-gemini-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Reddit seeking a valuation of up to $6.5 billi...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/reddit-seeking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NASA shuts down satellite refueling project af...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/nasa-shuts-dow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Fed Chair Powell and jobs data take center sta...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/fed-chair-powe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Here are the Nasdaqâ€™s most beloved stocks that...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/the-nasdaqs-mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What worked and didn't work this week from AI ...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/what-worked-di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Judge rejects AstraZenecaâ€™s challenge to Medic...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/medicare-drug-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What to know about this hot AI stock up nearly...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2024/03/01/people-didnt-s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              heading          date  \\\n",
       "0   We left the U.S. for Costa Rica and live bette...   3 Hours Ago   \n",
       "1   These are the 10 happiest cities in Americaâ€”no...   3 Hours Ago   \n",
       "2   The 3 most important things we're watching in ...   3 Hours Ago   \n",
       "3   Busy ER doctors say these 8 sleep tips help th...   3 Hours Ago   \n",
       "4   Why millionaires may have hit their Social Sec...   3 Hours Ago   \n",
       "5   College AI degree programs are booming.  Are t...   3 Hours Ago   \n",
       "6   Stocks enter 'belief' phase with most investor...   4 Hours Ago   \n",
       "7   Newlywed couple went $44,000 into credit card ...   4 Hours Ago   \n",
       "8   Immigration is 'taking pressure off' the job m...   4 Hours Ago   \n",
       "9   Venture capital firm's plan to buy nonprofit h...   4 Hours Ago   \n",
       "10  Top stocks to play the future of energy from a...   4 Hours Ago   \n",
       "11  Ride the bull market with these undervalued st...   4 Hours Ago   \n",
       "12                 How NescafÃ© instant coffee is made   5 Hours Ago   \n",
       "13  Upstart airlines Avelo and Breeze prepare for ...   5 Hours Ago   \n",
       "14  OpenAI says in memo that Musk's claims â€˜stem f...  14 Hours Ago   \n",
       "15  Waymo wins approval to expand robotaxi service...  17 Hours Ago   \n",
       "16  CEO explains why RadNet is piloting mammogram ...  18 Hours Ago   \n",
       "17  Cramer's Lightning Round: 'Not recommending' G...  18 Hours Ago   \n",
       "18  Cramer's week ahead: Watch for earnings from T...  18 Hours Ago   \n",
       "19  Super Micro joining S&P 500 after stock price ...  18 Hours Ago   \n",
       "20  Change Healthcare sets up a new electronic pre...  19 Hours Ago   \n",
       "21  Lockheed Martin looks to acquire spacecraft ma...  19 Hours Ago   \n",
       "22  Google Gemini head removes social media profil...  20 Hours Ago   \n",
       "23  Reddit seeking a valuation of up to $6.5 billi...  21 Hours Ago   \n",
       "24  NASA shuts down satellite refueling project af...  21 Hours Ago   \n",
       "25  Fed Chair Powell and jobs data take center sta...  21 Hours Ago   \n",
       "26  Here are the Nasdaqâ€™s most beloved stocks that...  22 Hours Ago   \n",
       "27  What worked and didn't work this week from AI ...  22 Hours Ago   \n",
       "28  Judge rejects AstraZenecaâ€™s challenge to Medic...  23 Hours Ago   \n",
       "29  What to know about this hot AI stock up nearly...  23 Hours Ago   \n",
       "\n",
       "                                                 link  \n",
       "0   https://www.cnbc.com/2024/03/02/we-left-the-us...  \n",
       "1   https://www.cnbc.com/2024/03/02/happiest-citie...  \n",
       "2   https://www.cnbc.com/2024/03/02/the-3-most-imp...  \n",
       "3   https://www.cnbc.com/2024/03/02/busy-er-doctor...  \n",
       "4   https://www.cnbc.com/2024/03/02/millionaires-r...  \n",
       "5   https://www.cnbc.com/2024/03/02/college-ai-deg...  \n",
       "6   https://www.cnbc.com/2024/03/02/stocks-enter-b...  \n",
       "7   https://www.cnbc.com/2024/03/02/newlyweds-went...  \n",
       "8   https://www.cnbc.com/2024/03/02/immigration-ta...  \n",
       "9   https://www.cnbc.com/2024/03/02/heres-why-gene...  \n",
       "10  https://www.cnbc.com/2024/03/02/top-stocks-to-...  \n",
       "11  https://www.cnbc.com/2024/03/02/ride-the-bull-...  \n",
       "12  https://www.cnbc.com/2024/03/02/how-nescaf-ins...  \n",
       "13  https://www.cnbc.com/2024/03/02/upstart-airlin...  \n",
       "14  https://www.cnbc.com/2024/03/01/openai-says-mu...  \n",
       "15  https://www.cnbc.com/2024/03/01/waymo-approved...  \n",
       "16  https://www.cnbc.com/2024/03/01/ceo-explains-w...  \n",
       "17  https://www.cnbc.com/2024/03/01/cramers-lightn...  \n",
       "18  https://www.cnbc.com/2024/03/01/cramers-week-a...  \n",
       "19  https://www.cnbc.com/2024/03/01/super-micro-jo...  \n",
       "20  https://www.cnbc.com/2024/03/01/change-healthc...  \n",
       "21  https://www.cnbc.com/2024/03/01/lockheed-marti...  \n",
       "22  https://www.cnbc.com/2024/03/01/google-gemini-...  \n",
       "23  https://www.cnbc.com/2024/03/01/reddit-seeking...  \n",
       "24  https://www.cnbc.com/2024/03/01/nasa-shuts-dow...  \n",
       "25  https://www.cnbc.com/2024/03/01/fed-chair-powe...  \n",
       "26  https://www.cnbc.com/2024/03/01/the-nasdaqs-mo...  \n",
       "27  https://www.cnbc.com/2024/03/01/what-worked-di...  \n",
       "28  https://www.cnbc.com/2024/03/01/medicare-drug-...  \n",
       "29  https://www.cnbc.com/2024/03/01/people-didnt-s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url= \"https://www.cnbc.com/world/?region=world\" \n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "heading=[]\n",
    "link=[]\n",
    "for i in soup.find_all(\"a\",class_=\"LatestNews-headline\"):\n",
    "    heading.append(i.text)\n",
    "    link.append(i.get('href'))\n",
    "\n",
    "date=[]\n",
    "for i in soup.find_all(\"time\",class_=\"LatestNews-timestamp\"):\n",
    "    date.append(i.text)\n",
    "\n",
    "    \n",
    "\n",
    "df=pd.DataFrame({\"heading\":heading,\"date\":date,\"link\":link})\n",
    "df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f71f414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>papertitle</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\r\\n                    Implementation of ar...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Tanha Talaviya |  Dhara Shah |  Nivedita Pate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\r\\n                    Review of agricultur...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Jinyuan Xu |  Baoxing Gu |  Guangzhao Tian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\r\\n                    A comprehensive revi...</td>\n",
       "      <td>June 2019</td>\n",
       "      <td>Kirtan Jha |  Aalap Doshi |  Poojan Patel |  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\r\\n                    Automation and digit...</td>\n",
       "      <td>2021</td>\n",
       "      <td>A. Subeesh |  C.R. Mehta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\r\\n                    Applications of elec...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Juzhong Tan |  Jie Xu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\r\\n                    Fruit ripeness class...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>Matteo Rizzo |  Matteo Marcuzzo |  Alessandro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\r\\n                    A review of imaging ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Vijai Singh |  Namita Sharma |  Shikha Singh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n\\r\\n                    Deep learning based ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>V.G. Dhanya |  A. Subeesh |  N.L. Kushwaha | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\r\\n                    Comparison of CNN-ba...</td>\n",
       "      <td>September 2023</td>\n",
       "      <td>Md Taimur Ahad |  Yan Li |  Bo Song |  Touhid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n\\r\\n                    Transfer Learning fo...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Ananda S. Paymode |  Vandana B. Malode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\n\\r\\n                    Plant disease detect...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Punam Bedi |  Pushkar Gole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\n\\r\\n                    Machine learning in ...</td>\n",
       "      <td>September 2023</td>\n",
       "      <td>Oumnia Ennaji |  Leonardus VergÃ¼tz |  Achraf ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\n\\r\\n                    DeepRice: A deep lea...</td>\n",
       "      <td>March 2024</td>\n",
       "      <td>P. Isaac Ritharson |  Kumudha Raimond |  X. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\n\\r\\n                    How artificial intel...</td>\n",
       "      <td>June 2023</td>\n",
       "      <td>Vilani Sachithra |  L.D.C.S. Subhashini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\n\\r\\n                    Machine learning for...</td>\n",
       "      <td>December 2023</td>\n",
       "      <td>Filbert H. Juwono |  W.K. Wong |  Seema Verma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\n\\r\\n                    Examining the interp...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Abderahman Rejeb |  Karim Rejeb |  Suhaiza Za...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\\n\\r\\n                    Deep convolutional n...</td>\n",
       "      <td>2022</td>\n",
       "      <td>A. Subeesh |  S. Bhole |  K. Singh |  N.S. Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\n\\r\\n                    A systematic review ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Md Ekramul Hossain |  Muhammad Ashad Kabir | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\n\\r\\n                    A review on computer...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Cedric Okinda |  Innocent Nyalala |  Tchalla ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\n\\r\\n                    Crop diagnostic syst...</td>\n",
       "      <td>December 2023</td>\n",
       "      <td>R. Abbasi |  P. Martinez |  R. Ahmad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\n\\r\\n                    Artificial cognition...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Misbah Pathan |  Nivedita Patel |  Hiteshri Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\n\\r\\n                    Explainable artifici...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Masahiro Ryo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\n\\r\\n                    Blockchain: A new sa...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jie Xu |  Shuang Guo |  David Xie |  Yaxuan Yan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\\n\\r\\n                    Study on body temper...</td>\n",
       "      <td>March 2019</td>\n",
       "      <td>Zaiqin Zhang |  Hang Zhang |  Tonghai Liu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\\n\\r\\n                    Vision Intelligence ...</td>\n",
       "      <td>March 2024</td>\n",
       "      <td>Galib Muhammad Shahriar Himel |  Md. Masudul ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           papertitle            date  \\\n",
       "0   \\n\\r\\n                    Implementation of ar...            2020   \n",
       "1   \\n\\r\\n                    Review of agricultur...            2022   \n",
       "2   \\n\\r\\n                    A comprehensive revi...       June 2019   \n",
       "3   \\n\\r\\n                    Automation and digit...            2021   \n",
       "4   \\n\\r\\n                    Applications of elec...            2020   \n",
       "5   \\n\\r\\n                    Fruit ripeness class...      March 2023   \n",
       "6   \\n\\r\\n                    A review of imaging ...            2020   \n",
       "7   \\n\\r\\n                    Deep learning based ...            2022   \n",
       "8   \\n\\r\\n                    Comparison of CNN-ba...  September 2023   \n",
       "9   \\n\\r\\n                    Transfer Learning fo...            2022   \n",
       "10  \\n\\r\\n                    Plant disease detect...            2021   \n",
       "11  \\n\\r\\n                    Machine learning in ...  September 2023   \n",
       "12  \\n\\r\\n                    DeepRice: A deep lea...      March 2024   \n",
       "13  \\n\\r\\n                    How artificial intel...       June 2023   \n",
       "14  \\n\\r\\n                    Machine learning for...   December 2023   \n",
       "15  \\n\\r\\n                    Examining the interp...            2022   \n",
       "16  \\n\\r\\n                    Deep convolutional n...            2022   \n",
       "17  \\n\\r\\n                    A systematic review ...            2022   \n",
       "18  \\n\\r\\n                    A review on computer...            2020   \n",
       "19  \\n\\r\\n                    Crop diagnostic syst...   December 2023   \n",
       "20  \\n\\r\\n                    Artificial cognition...            2020   \n",
       "21  \\n\\r\\n                    Explainable artifici...            2022   \n",
       "22  \\n\\r\\n                    Blockchain: A new sa...            2020   \n",
       "23  \\n\\r\\n                    Study on body temper...      March 2019   \n",
       "24  \\n\\r\\n                    Vision Intelligence ...      March 2024   \n",
       "\n",
       "                                               author  \n",
       "0    Tanha Talaviya |  Dhara Shah |  Nivedita Pate...  \n",
       "1          Jinyuan Xu |  Baoxing Gu |  Guangzhao Tian  \n",
       "2    Kirtan Jha |  Aalap Doshi |  Poojan Patel |  ...  \n",
       "3                            A. Subeesh |  C.R. Mehta  \n",
       "4                               Juzhong Tan |  Jie Xu  \n",
       "5    Matteo Rizzo |  Matteo Marcuzzo |  Alessandro...  \n",
       "6        Vijai Singh |  Namita Sharma |  Shikha Singh  \n",
       "7    V.G. Dhanya |  A. Subeesh |  N.L. Kushwaha | ...  \n",
       "8    Md Taimur Ahad |  Yan Li |  Bo Song |  Touhid...  \n",
       "9              Ananda S. Paymode |  Vandana B. Malode  \n",
       "10                         Punam Bedi |  Pushkar Gole  \n",
       "11   Oumnia Ennaji |  Leonardus VergÃ¼tz |  Achraf ...  \n",
       "12   P. Isaac Ritharson |  Kumudha Raimond |  X. A...  \n",
       "13            Vilani Sachithra |  L.D.C.S. Subhashini  \n",
       "14   Filbert H. Juwono |  W.K. Wong |  Seema Verma...  \n",
       "15   Abderahman Rejeb |  Karim Rejeb |  Suhaiza Za...  \n",
       "16   A. Subeesh |  S. Bhole |  K. Singh |  N.S. Ch...  \n",
       "17   Md Ekramul Hossain |  Muhammad Ashad Kabir | ...  \n",
       "18   Cedric Okinda |  Innocent Nyalala |  Tchalla ...  \n",
       "19               R. Abbasi |  P. Martinez |  R. Ahmad  \n",
       "20   Misbah Pathan |  Nivedita Patel |  Hiteshri Y...  \n",
       "21                                       Masahiro Ryo  \n",
       "22    Jie Xu |  Shuang Guo |  David Xie |  Yaxuan Yan  \n",
       "23          Zaiqin Zhang |  Hang Zhang |  Tonghai Liu  \n",
       "24   Galib Muhammad Shahriar Himel |  Md. Masudul ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url= \"https://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/most-downloaded-articles/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "papertitle=[]\n",
    "for i in soup.find_all(\"h2\",class_=\"h5 article-title\"):\n",
    "    papertitle.append(i.text)\n",
    "date=[]\n",
    "for i in soup.find_all(\"p\",class_=\"article-date\"):\n",
    "    date.append(i.text)\n",
    "    \n",
    "author=[]\n",
    "for i in soup.find_all(\"p\",class_=\"article-authors\"):\n",
    "    author.append(i.text)\n",
    "\n",
    "\n",
    "    \n",
    "df=pd.DataFrame({\"papertitle\":papertitle,\"date\":date,\"author\":author})\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a4617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
